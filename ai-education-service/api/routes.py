"""
API è·¯ç”±å®šä¹‰
"""

import json
import logging
from pathlib import Path
from fastapi import APIRouter, Depends, HTTPException, status, BackgroundTasks, Query
from fastapi.responses import StreamingResponse, HTMLResponse, FileResponse

from .schemas import (
    ProcessDocumentRequest,
    ProcessDocumentResponse,
    HealthResponse,
    ErrorResponse,
    SearchRequest,
    SearchResponse,
    SearchResult,
    ChatRequest,
    ChatResponse,
)
from .dependencies import verify_api_key
from modules import ProcessingPipeline, RAGRetriever
from modules.conversation_memory import get_memory
from modules.rag_workflow import (
    RAGWorkflow, RAGStreamWorkflow,
    get_rag_workflow, get_rag_stream_workflow,
    generate_workflow_diagram, generate_execution_trace
)
from modules.document_workflow import (
    DocumentProcessingWorkflow,
    get_document_workflow
)
from config import settings

logger = logging.getLogger(__name__)

router = APIRouter()

# å…¨å±€å®ä¾‹ï¼ˆå»¶è¿Ÿåˆå§‹åŒ–ï¼‰
_pipeline: ProcessingPipeline = None
_retriever: RAGRetriever = None


def get_pipeline() -> ProcessingPipeline:
    """è·å–å¤„ç†ç®¡é“å®ä¾‹"""
    global _pipeline
    if _pipeline is None:
        _pipeline = ProcessingPipeline()
    return _pipeline


def get_retriever() -> RAGRetriever:
    """è·å– RAG æ£€ç´¢å™¨å®ä¾‹"""
    global _retriever
    if _retriever is None:
        _retriever = RAGRetriever()
    return _retriever


@router.get(
    "/health",
    response_model=HealthResponse,
    summary="å¥åº·æ£€æŸ¥",
    description="æ£€æŸ¥æœåŠ¡æ˜¯å¦æ­£å¸¸è¿è¡Œ"
)
async def health_check():
    """å¥åº·æ£€æŸ¥ç«¯ç‚¹"""
    return HealthResponse(
        status="healthy",
        version=settings.APP_VERSION
    )


@router.post(
    "/process-document",
    response_model=ProcessDocumentResponse,
    responses={
        200: {"model": ProcessDocumentResponse, "description": "å¤„ç†æˆåŠŸ"},
        400: {"model": ErrorResponse, "description": "è¯·æ±‚å‚æ•°é”™è¯¯"},
        401: {"model": ErrorResponse, "description": "è®¤è¯å¤±è´¥"},
        500: {"model": ErrorResponse, "description": "æœåŠ¡å™¨å†…éƒ¨é”™è¯¯"}
    },
    summary="å¤„ç†æ–‡æ¡£",
    description="ä» OSS ä¸‹è½½æ–‡æ¡£ï¼Œè¿›è¡Œè§£æã€åˆ†å—ã€å‘é‡åŒ–ï¼Œå¹¶å­˜å‚¨åˆ°å‘é‡æ•°æ®åº“"
)
async def process_document(
    request: ProcessDocumentRequest,
    _: bool = Depends(verify_api_key)
):
    """
    å¤„ç†æ–‡æ¡£ç«¯ç‚¹
    
    æ¥æ”¶ OSS æ–‡ä»¶ä¿¡æ¯ï¼Œæ‰§è¡Œå®Œæ•´çš„å¤„ç†æµç¨‹ï¼š
    1. ä» OSS ä¸‹è½½æ–‡ä»¶
    2. ä½¿ç”¨ LlamaIndex è§£ææ–‡æ¡£
    3. æ–‡æœ¬åˆ†å—
    4. ç”Ÿæˆå‘é‡ï¼ˆé€šè¿‡ OpenRouterï¼‰
    5. å­˜å‚¨åˆ° DashVector
    """
    try:
        logger.info(f"æ”¶åˆ°å¤„ç†è¯·æ±‚: {request.oss_key}")
        
        pipeline = get_pipeline()
        result = pipeline.process(
            oss_key=request.oss_key,
            bucket=request.bucket,
            metadata=request.metadata
        )
        
        if result.success:
            return ProcessDocumentResponse(
                success=True,
                message=result.message,
                data=result.to_dict()
            )
        else:
            return ProcessDocumentResponse(
                success=False,
                message=result.message,
                data=result.to_dict()
            )
            
    except Exception as e:
        logger.error(f"å¤„ç†æ–‡æ¡£æ—¶å‘ç”Ÿé”™è¯¯: {e}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=str(e)
        )


@router.post(
    "/process-document/async",
    response_model=ProcessDocumentResponse,
    summary="å¼‚æ­¥å¤„ç†æ–‡æ¡£",
    description="å¼‚æ­¥å¤„ç†æ–‡æ¡£ï¼Œç«‹å³è¿”å›ï¼Œåå°æ‰§è¡Œå¤„ç†"
)
async def process_document_async(
    request: ProcessDocumentRequest,
    background_tasks: BackgroundTasks,
    _: bool = Depends(verify_api_key)
):
    """
    å¼‚æ­¥å¤„ç†æ–‡æ¡£ç«¯ç‚¹
    
    ç«‹å³è¿”å›å“åº”ï¼Œåœ¨åå°æ‰§è¡Œå¤„ç†ä»»åŠ¡ã€‚
    é€‚ç”¨äºå¤§æ–‡ä»¶å¤„ç†åœºæ™¯ã€‚
    """
    def background_process():
        try:
            pipeline = get_pipeline()
            result = pipeline.process(
                oss_key=request.oss_key,
                bucket=request.bucket,
                metadata=request.metadata
            )
            logger.info(f"åå°å¤„ç†å®Œæˆ: {request.oss_key}, ç»“æœ: {result.success}")
        except Exception as e:
            logger.error(f"åå°å¤„ç†å¤±è´¥: {request.oss_key}, é”™è¯¯: {e}")
    
    background_tasks.add_task(background_process)
    
    return ProcessDocumentResponse(
        success=True,
        message="ä»»åŠ¡å·²æäº¤ï¼Œæ­£åœ¨åå°å¤„ç†",
        data={
            "status": "pending",
            "file_key": request.oss_key
        }
    )


# ==================== RAG æ£€ç´¢æ¥å£ ====================

@router.post(
    "/search",
    response_model=SearchResponse,
    summary="å‘é‡æ£€ç´¢",
    description="æ ¹æ®æŸ¥è¯¢æ–‡æœ¬æ£€ç´¢ç›¸å…³æ–‡æ¡£ç‰‡æ®µ"
)
async def search(
    request: SearchRequest,
    _: bool = Depends(verify_api_key)
):
    """
    å‘é‡æ£€ç´¢ç«¯ç‚¹

    æ ¹æ®ç”¨æˆ·æŸ¥è¯¢ç”Ÿæˆå‘é‡ï¼Œåœ¨å‘é‡æ•°æ®åº“ä¸­æ£€ç´¢ç›¸ä¼¼æ–‡æ¡£ç‰‡æ®µã€‚
    """
    try:
        logger.info(f"æ”¶åˆ°æ£€ç´¢è¯·æ±‚: {request.query[:50]}...")

        retriever = get_retriever()
        results = retriever.retrieve(
            query=request.query,
            top_k=request.top_k,
            filter_expr=request.filter_expr
        )

        # è½¬æ¢ä¸ºå“åº”æ ¼å¼
        search_results = [
            SearchResult(
                id=r["id"],
                text=r["text"],
                score=r["score"],
                metadata=r.get("metadata")
            )
            for r in results
        ]

        return SearchResponse(
            success=True,
            results=search_results,
            total=len(search_results)
        )

    except Exception as e:
        logger.error(f"æ£€ç´¢æ—¶å‘ç”Ÿé”™è¯¯: {e}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=str(e)
        )


@router.post(
    "/chat",
    response_model=ChatResponse,
    summary="RAG é—®ç­”",
    description="åŸºäºæ£€ç´¢å¢å¼ºç”Ÿæˆï¼ˆRAGï¼‰çš„æ™ºèƒ½é—®ç­”"
)
async def chat(
    request: ChatRequest,
    _: bool = Depends(verify_api_key)
):
    """
    RAG é—®ç­”ç«¯ç‚¹

    å®Œæ•´çš„ RAG æµç¨‹ï¼š
    1. æ ¹æ®é—®é¢˜æ£€ç´¢ç›¸å…³æ–‡æ¡£
    2. æ„å»ºä¸Šä¸‹æ–‡
    3. è°ƒç”¨å¤§æ¨¡å‹ç”Ÿæˆå›ç­”
    """
    try:
        logger.info(f"æ”¶åˆ°é—®ç­”è¯·æ±‚: {request.question[:50]}...")

        retriever = get_retriever()

        # è½¬æ¢å†å²å¯¹è¯æ ¼å¼
        history = None
        if request.history:
            history = [{"role": msg.role, "content": msg.content} for msg in request.history]

        # ğŸ”§ æœ€ç»ˆä¿®æ­£ï¼šå¼ºåˆ¶ system_prompt=Noneï¼Œç¡®ä¿å¼•ç”¨è§„åˆ™ä¸è¢«è¦†ç›–
        result = await retriever.query(
            question=request.question,
            top_k=request.top_k,
            filter_expr=request.filter_expr,
            system_prompt=None,  # â† å¼ºåˆ¶ä¸º Noneï¼ç¦æ­¢è¦†ç›–å¼•ç”¨è§„åˆ™
            history=history,
            user_id=request.user_id,
            book_id=request.book_id
        )

        # è½¬æ¢æ¥æºä¸ºå“åº”æ ¼å¼
        sources = [
            SearchResult(
                id=s["id"],
                text=s["text"],
                score=s["score"],
                metadata=s.get("metadata")
            )
            for s in result.get("sources", [])
        ]

        return ChatResponse(
            success=True,
            answer=result["answer"],
            sources=sources,
            has_context=result["has_context"]
        )

    except Exception as e:
        logger.error(f"é—®ç­”æ—¶å‘ç”Ÿé”™è¯¯: {e}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=str(e)
        )


@router.post(
    "/chat/stream",
    summary="RAG æµå¼é—®ç­”",
    description="åŸºäºæ£€ç´¢å¢å¼ºç”Ÿæˆï¼ˆRAGï¼‰çš„æ™ºèƒ½é—®ç­”ï¼Œæµå¼è¾“å‡ºï¼Œæ”¯æŒå¤šè½®å¯¹è¯å’Œé•¿æœŸè®°å¿†"
)
async def chat_stream(
    request: ChatRequest,
    _: bool = Depends(verify_api_key)
):
    """
    RAG æµå¼é—®ç­”ç«¯ç‚¹ï¼ˆæ”¯æŒå¤šè½®å¯¹è¯ + é•¿æœŸè®°å¿†ï¼‰

    è¿”å› SSE æ ¼å¼çš„æµå¼å“åº”ï¼š
    - event: sources - æ£€ç´¢åˆ°çš„å‚è€ƒæ¥æº
    - event: content - AI ç”Ÿæˆçš„å†…å®¹ç‰‡æ®µ
    - event: done - å®Œæˆæ ‡è®°

    å¤šè½®å¯¹è¯ç‰¹æ€§ï¼š
    - æ‡’æƒ°å‹ç¼©ï¼šå†å²è¶…è¿‡é˜ˆå€¼æ—¶è‡ªåŠ¨ç”Ÿæˆæ‘˜è¦
    - æŸ¥è¯¢æ”¹å†™ï¼šè§£å†³æŒ‡ä»£ä¸æ¸…é—®é¢˜ï¼ˆå¦‚"å®ƒ"ã€"è¿™ä¸ª"ï¼‰
    - ä¸Šä¸‹æ–‡éš”ç¦»ï¼šé€šè¿‡ book_id éš”ç¦»ä¸åŒå­¦ç§‘çš„è®°å¿†
    - é•¿æœŸè®°å¿†ï¼šæ‘˜è¦å­˜å‚¨åœ¨ Redis/å†…å­˜ä¸­ï¼ŒKey: summary_{user_id}_{book_id}
    """
    try:
        retriever = get_retriever()
        memory = get_memory()

        # è½¬æ¢å†å²å¯¹è¯æ ¼å¼
        history = []
        if request.history:
            history = [{"role": msg.role, "content": msg.content} for msg in request.history]

        # è·å– user_id å’Œ book_idï¼ˆç”¨äºé•¿æœŸè®°å¿†ï¼‰
        user_id = request.user_id or "anonymous"
        book_id = request.book_id or "default"

        logger.info(f"æ”¶åˆ°æµå¼é—®ç­”è¯·æ±‚: {request.question[:50]}..., user={user_id}, book={book_id}, å†å²: {len(history)} æ¡")

        # 1. æ£€æŸ¥å¹¶å‹ç¼©å¯¹è¯å†å²ï¼ˆæ‡’æƒ°æ¨¡å¼ï¼‰
        compressed_history, summary = await memory.check_and_compress(user_id, book_id, history)
        if summary:
            logger.info(f"å·²è·å–å¯¹è¯æ‘˜è¦ï¼Œé•¿åº¦: {len(summary)}")

        # 2. æŸ¥è¯¢æ”¹å†™ï¼ˆç»“åˆæ‘˜è¦ä¸Šä¸‹æ–‡ï¼‰
        rewrite_context = compressed_history.copy()
        if summary:
            rewrite_context.insert(0, {"role": "system", "content": f"[ä¹‹å‰çš„å¯¹è¯æ‘˜è¦]: {summary}"})
        rewritten_query = await retriever.rewrite_query(request.question, rewrite_context)

        # 3. ä½¿ç”¨æ”¹å†™åçš„æŸ¥è¯¢æ£€ç´¢ç›¸å…³æ–‡æ¡£
        results = retriever.retrieve(
            query=rewritten_query,
            top_k=request.top_k,
            filter_expr=request.filter_expr  # ä¿ç•™ book_id è¿‡æ»¤ï¼Œç¡®ä¿ä¸è·‘é¢˜
        )

        # 4. æ„å»ºä¸Šä¸‹æ–‡ï¼ˆå¸¦å¼•ç”¨æ ‡è®° [æ¥æºX]ï¼‰
        # build_context è¿”å› (context_str, used_results)
        context, used_results = retriever.build_context(results)
        has_context = len(used_results) > 0

        # è½¬æ¢æ¥æºä¸ºå“åº”æ ¼å¼ï¼ˆä½¿ç”¨ used_resultsï¼ŒåŒ…å« citation_idï¼‰
        sources = [
            {
                "id": r["id"],
                "text": r["text"],
                "score": r["score"],
                "metadata": r.get("metadata"),
                "citation_id": r.get("citation_id", i + 1)  # å¼•ç”¨ç¼–å·
            }
            for i, r in enumerate(used_results)
        ]

        async def generate():
            # å…ˆå‘é€ sources
            yield f"event: sources\ndata: {json.dumps({'sources': sources, 'has_context': has_context}, ensure_ascii=False)}\n\n"

            # ğŸš¨ ã€ä¿®æ”¹ç‚¹ã€‘ç§»é™¤ "if not has_context" çš„æ‹¦æˆªåˆ¤æ–­
            # æ— è®ºæ˜¯å¦æœ‰ä¸Šä¸‹æ–‡ï¼Œéƒ½è°ƒç”¨ generate_answer_stream
            # è®© LLM è‡ªå·±æ ¹æ® System Prompt å†³å®šï¼šæ˜¯å›ç­”"ä¸çŸ¥é“"ï¼Œè¿˜æ˜¯æ ¹æ®"å†å²å¯¹è¯"å›ç­”
            async for chunk in retriever.generate_answer_stream(
                query=request.question,
                context=context,     # å³ä½¿æ˜¯ç©ºå­—ç¬¦ä¸²ä¹Ÿæ²¡å…³ç³»
                system_prompt=None,  # â† å¼ºåˆ¶ä¸º Noneï¼ç¦æ­¢ API å±‚è¦†ç›–å¼•ç”¨è§„åˆ™
                history=compressed_history,
                summary=summary      # â† ç‹¬ç«‹ä¼ é€’ï¼Œç”± retriever èåˆåˆ° prompt
            ):
                yield f"event: content\ndata: {json.dumps({'content': chunk}, ensure_ascii=False)}\n\n"

            # å‘é€å®Œæˆæ ‡è®°
            yield f"event: done\ndata: {json.dumps({'done': True})}\n\n"

        return StreamingResponse(
            generate(),
            media_type="text/event-stream",
            headers={
                "Cache-Control": "no-cache",
                "Connection": "keep-alive",
                "X-Accel-Buffering": "no",
            }
        )

    except Exception as e:
        logger.error(f"æµå¼é—®ç­”æ—¶å‘ç”Ÿé”™è¯¯: {e}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=str(e)
        )


# ==================== å‘é‡ç®¡ç†æ¥å£ ====================

@router.delete(
    "/vectors/{book_id}",
    summary="åˆ é™¤å›¾ä¹¦å‘é‡",
    description="åˆ é™¤æŒ‡å®šå›¾ä¹¦çš„æ‰€æœ‰å‘é‡æ•°æ®"
)
async def delete_vectors(
    book_id: str,
    _: bool = Depends(verify_api_key)
):
    """
    åˆ é™¤å›¾ä¹¦å‘é‡ç«¯ç‚¹

    æ ¹æ® book_id åˆ é™¤è¯¥å›¾ä¹¦çš„æ‰€æœ‰å‘é‡æ•°æ®ã€‚
    ç”¨äºå›¾ä¹¦åˆ é™¤æˆ–æ›´æ–°æ—¶æ¸…ç†æ—§æ•°æ®ã€‚
    """
    try:
        logger.info(f"æ”¶åˆ°åˆ é™¤å‘é‡è¯·æ±‚: book_id={book_id}")

        retriever = get_retriever()
        success = retriever.vector_store.delete_by_filter(f"book_id = '{book_id}'")

        return {
            "success": success,
            "message": "å‘é‡åˆ é™¤æˆåŠŸ" if success else "å‘é‡åˆ é™¤å¤±è´¥",
            "book_id": book_id
        }

    except Exception as e:
        logger.error(f"åˆ é™¤å‘é‡æ—¶å‘ç”Ÿé”™è¯¯: {e}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=str(e)
        )


# ==================== Workflow å¯è§†åŒ–æ¥å£ ====================

@router.get(
    "/workflow/visualize",
    response_class=HTMLResponse,
    summary="å·¥ä½œæµå¯è§†åŒ–",
    description="ç”Ÿæˆå¹¶è¿”å›å·¥ä½œæµçš„å¯è§†åŒ–å›¾è¡¨ï¼ˆHTML æ ¼å¼ï¼‰"
)
async def visualize_workflow(
    workflow_type: str = Query(
        default="rag",
        description="å·¥ä½œæµç±»å‹: rag, rag_stream, document"
    ),
    _: bool = Depends(verify_api_key)
):
    """
    å·¥ä½œæµå¯è§†åŒ–ç«¯ç‚¹

    ç”ŸæˆæŒ‡å®šå·¥ä½œæµçš„äº¤äº’å¼æµç¨‹å›¾ï¼ˆHTML æ ¼å¼ï¼‰ã€‚

    æ”¯æŒçš„å·¥ä½œæµç±»å‹ï¼š
    - rag: RAG é—®ç­”å·¥ä½œæµ
    - rag_stream: RAG æµå¼é—®ç­”å·¥ä½œæµ
    - document: æ–‡æ¡£å¤„ç†å·¥ä½œæµ
    """
    try:
        workflow_map = {
            "rag": RAGWorkflow,
            "rag_stream": RAGStreamWorkflow,
            "document": DocumentProcessingWorkflow
        }

        if workflow_type not in workflow_map:
            raise HTTPException(
                status_code=status.HTTP_400_BAD_REQUEST,
                detail=f"ä¸æ”¯æŒçš„å·¥ä½œæµç±»å‹: {workflow_type}ï¼Œæ”¯æŒ: {list(workflow_map.keys())}"
            )

        workflow_class = workflow_map[workflow_type]
        filename = f"workflow_{workflow_type}.html"

        # ç”Ÿæˆæµç¨‹å›¾
        result_path = generate_workflow_diagram(workflow_class, filename)

        if not result_path or not Path(result_path).exists():
            raise HTTPException(
                status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
                detail="ç”Ÿæˆæµç¨‹å›¾å¤±è´¥ï¼Œè¯·ç¡®ä¿å·²å®‰è£… llama-index-utils-workflow"
            )

        # è¯»å–å¹¶è¿”å› HTML å†…å®¹
        with open(result_path, "r", encoding="utf-8") as f:
            html_content = f.read()

        return HTMLResponse(content=html_content)

    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"ç”Ÿæˆå·¥ä½œæµå¯è§†åŒ–æ—¶å‘ç”Ÿé”™è¯¯: {e}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=str(e)
        )


@router.get(
    "/workflow/info",
    summary="å·¥ä½œæµä¿¡æ¯",
    description="è·å–æ‰€æœ‰å¯ç”¨å·¥ä½œæµçš„ä¿¡æ¯"
)
async def workflow_info(
    _: bool = Depends(verify_api_key)
):
    """
    è·å–å·¥ä½œæµä¿¡æ¯ç«¯ç‚¹

    è¿”å›æ‰€æœ‰å¯ç”¨å·¥ä½œæµçš„æè¿°å’Œæ­¥éª¤ä¿¡æ¯ã€‚
    """
    return {
        "workflows": [
            {
                "type": "rag",
                "name": "RAG é—®ç­”å·¥ä½œæµ",
                "description": "äº‹ä»¶é©±åŠ¨çš„ RAG é—®ç­”æµç¨‹",
                "steps": [
                    "rewrite_query - æŸ¥è¯¢æ”¹å†™ï¼ˆè§£å†³æŒ‡ä»£é—®é¢˜ï¼‰",
                    "retrieve - å‘é‡æ£€ç´¢",
                    "rerank - é‡æ’åºï¼ˆå¯é€‰ï¼‰",
                    "build_context - æ„å»ºä¸Šä¸‹æ–‡",
                    "generate_answer - ç”Ÿæˆå›ç­”"
                ]
            },
            {
                "type": "rag_stream",
                "name": "RAG æµå¼é—®ç­”å·¥ä½œæµ",
                "description": "æ”¯æŒ SSE æµå¼è¾“å‡ºçš„ RAG é—®ç­”æµç¨‹",
                "steps": [
                    "rewrite_query - æŸ¥è¯¢æ”¹å†™",
                    "retrieve - å‘é‡æ£€ç´¢",
                    "rerank - é‡æ’åº",
                    "build_context - æ„å»ºä¸Šä¸‹æ–‡",
                    "prepare_stream - å‡†å¤‡æµå¼ç”Ÿæˆ"
                ]
            },
            {
                "type": "document",
                "name": "æ–‡æ¡£å¤„ç†å·¥ä½œæµ",
                "description": "äº‹ä»¶é©±åŠ¨çš„æ–‡æ¡£å¤„ç†æµç¨‹",
                "steps": [
                    "validate - éªŒè¯æ–‡ä»¶ç±»å‹",
                    "download - ä» OSS ä¸‹è½½",
                    "process_document - è§£æå’Œåˆ†å—",
                    "store_vectors - å­˜å‚¨å‘é‡",
                    "cleanup_success/cleanup_failed - æ¸…ç†ä¸´æ—¶æ–‡ä»¶"
                ]
            }
        ],
        "visualization_url": "/api/workflow/visualize?workflow_type={type}"
    }


# ==================== Workflow ç‰ˆæœ¬çš„æ¥å£ï¼ˆå¯é€‰å¯ç”¨ï¼‰====================

@router.post(
    "/v2/chat",
    response_model=ChatResponse,
    summary="RAG é—®ç­” (Workflow ç‰ˆæœ¬)",
    description="ä½¿ç”¨ LlamaIndex Workflows å®ç°çš„ RAG é—®ç­”"
)
async def chat_v2(
    request: ChatRequest,
    _: bool = Depends(verify_api_key)
):
    """
    Workflow ç‰ˆæœ¬çš„ RAG é—®ç­”ç«¯ç‚¹

    ä½¿ç”¨äº‹ä»¶é©±åŠ¨çš„å·¥ä½œæµæ¶æ„ï¼Œæä¾›æ›´å¥½çš„å¯è§‚æµ‹æ€§å’Œé”™è¯¯å¤„ç†ã€‚
    """
    try:
        logger.info(f"[Workflow] æ”¶åˆ°é—®ç­”è¯·æ±‚: {request.question[:50]}...")

        workflow = get_rag_workflow()

        # è½¬æ¢å†å²å¯¹è¯æ ¼å¼
        history = None
        if request.history:
            history = [{"role": msg.role, "content": msg.content} for msg in request.history]

        # è¿è¡Œå·¥ä½œæµ
        result = await workflow.run(
            query=request.question,
            history=history,
            user_id=request.user_id,
            book_id=request.book_id,
            filter_expr=request.filter_expr,
            top_k=request.top_k
        )

        # è½¬æ¢æ¥æºä¸ºå“åº”æ ¼å¼
        sources = [
            SearchResult(
                id=s["id"],
                text=s["text"],
                score=s["score"],
                metadata=s.get("metadata")
            )
            for s in result.get("sources", [])
        ]

        return ChatResponse(
            success=True,
            answer=result["answer"],
            sources=sources,
            has_context=result["has_context"]
        )

    except Exception as e:
        logger.error(f"[Workflow] é—®ç­”æ—¶å‘ç”Ÿé”™è¯¯: {e}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=str(e)
        )


@router.post(
    "/v2/chat/stream",
    summary="RAG æµå¼é—®ç­” (Workflow ç‰ˆæœ¬)",
    description="ä½¿ç”¨ LlamaIndex Workflows å®ç°çš„æµå¼ RAG é—®ç­”"
)
async def chat_stream_v2(
    request: ChatRequest,
    _: bool = Depends(verify_api_key)
):
    """
    Workflow ç‰ˆæœ¬çš„æµå¼ RAG é—®ç­”ç«¯ç‚¹

    ä½¿ç”¨äº‹ä»¶é©±åŠ¨çš„å·¥ä½œæµæ¶æ„ï¼Œè¿”å› SSE æ ¼å¼çš„æµå¼å“åº”ã€‚
    """
    try:
        logger.info(f"[Workflow] æ”¶åˆ°æµå¼é—®ç­”è¯·æ±‚: {request.question[:50]}...")

        workflow = get_rag_stream_workflow()

        # è½¬æ¢å†å²å¯¹è¯æ ¼å¼
        history = None
        if request.history:
            history = [{"role": msg.role, "content": msg.content} for msg in request.history]

        # è¿è¡Œå·¥ä½œæµè·å–å‡†å¤‡å¥½çš„æ•°æ®
        prep_result = await workflow.run(
            query=request.question,
            history=history,
            user_id=request.user_id,
            book_id=request.book_id,
            filter_expr=request.filter_expr,
            top_k=request.top_k
        )

        # æå–æµå¼ç”Ÿæˆæ‰€éœ€çš„æ•°æ®
        retriever = prep_result["retriever"]
        query = prep_result["query"]
        context = prep_result["context"]
        sources = prep_result["sources"]
        history = prep_result["history"]
        summary = prep_result["summary"]
        has_context = bool(context)

        # è½¬æ¢æ¥æºæ ¼å¼
        sources_data = [
            {
                "id": s["id"],
                "text": s["text"],
                "score": s["score"],
                "metadata": s.get("metadata"),
                "citation_id": s.get("citation_id", i + 1)
            }
            for i, s in enumerate(sources)
        ]

        async def generate():
            # å‘é€ sources
            yield f"event: sources\ndata: {json.dumps({'sources': sources_data, 'has_context': has_context}, ensure_ascii=False)}\n\n"

            # æµå¼ç”Ÿæˆå›ç­”
            async for chunk in retriever.generate_answer_stream(
                query=query,
                context=context,
                system_prompt=None,
                history=history,
                summary=summary
            ):
                yield f"event: content\ndata: {json.dumps({'content': chunk}, ensure_ascii=False)}\n\n"

            # å®Œæˆæ ‡è®°
            yield f"event: done\ndata: {json.dumps({'done': True})}\n\n"

        return StreamingResponse(
            generate(),
            media_type="text/event-stream",
            headers={
                "Cache-Control": "no-cache",
                "Connection": "keep-alive",
                "X-Accel-Buffering": "no",
            }
        )

    except Exception as e:
        logger.error(f"[Workflow] æµå¼é—®ç­”æ—¶å‘ç”Ÿé”™è¯¯: {e}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=str(e)
        )
