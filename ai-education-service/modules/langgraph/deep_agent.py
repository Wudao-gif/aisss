"""
Deep Agent ä¸»æ¨¡å—
ä½œä¸ºä¸»ç³»ç»Ÿæ›¿ä»£åŸæœ‰çš„ LangGraph Supervisor æ¶æ„

é…ç½®é¡¹ï¼š
- model: ä¸» LLM æ¨¡å‹
- tools: è‡ªå®šä¹‰å·¥å…·ï¼ˆæ£€ç´¢ã€è®°å¿†ç­‰ï¼‰
- system_prompt: ç³»ç»Ÿæç¤ºè¯
- subagents: å­ä»£ç†åˆ—è¡¨ï¼ˆåç»­é€ä¸ªæ¥å…¥ï¼‰
- checkpointer: çŸ­æœŸè®°å¿†æŒä¹…åŒ–
- store: é•¿æœŸè®°å¿†æŒä¹…åŒ–
- backend: æ–‡ä»¶ç³»ç»Ÿåç«¯
- middleware: ä¸­é—´ä»¶
- interrupt_on: äººæœºåä½œä¸­æ–­é…ç½®
"""

import logging
from typing import Dict, Any, Optional, List, AsyncGenerator

from deepagents import create_deep_agent, SubAgent
from langchain_openai import ChatOpenAI
from langgraph.checkpoint.base import BaseCheckpointSaver
from langgraph.store.base import BaseStore

from config import settings
from .tools import memory_read, memory_write
from .retrieval_subagent import create_retrieval_subagent

logger = logging.getLogger(__name__)


# ==================== ç³»ç»Ÿæç¤ºè¯ ====================

EDUCATION_SYSTEM_PROMPT = """ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ AI æ•™è‚²è¾…å¯¼åŠ©æ‰‹ï¼Œä¸“é—¨å¸®åŠ©å­¦ç”Ÿå­¦ä¹ æ•™æå†…å®¹ã€‚

## æ ¸å¿ƒå·¥ä½œæ–¹å¼ï¼šå…ˆè§„åˆ’ï¼Œåæ‰§è¡Œ

ä½ çš„å·¥ä½œæµç¨‹åº”è¯¥æ˜¯ï¼š
1. **æ„å›¾æ¾„æ¸…** - ç†è§£ç”¨æˆ·çš„çœŸå®éœ€æ±‚
2. **ä¿¡æ¯æ”¶é›†** - è¯¢é—®å¿…è¦çš„èƒŒæ™¯ä¿¡æ¯
3. **ä»»åŠ¡è§„åˆ’** - ä½¿ç”¨ write_todos åˆ¶å®šè¯¦ç»†è®¡åˆ’
4. **é€æ­¥æ‰§è¡Œ** - æŒ‰è®¡åˆ’é€ä¸ªå®Œæˆå­ä»»åŠ¡
5. **è®°å¿†ä¿å­˜** - ä½¿ç”¨ memory_write è®°å½•å­¦ä¹ æˆæœ

## é‡è¦åŸåˆ™

âš ï¸ **ä¸è¦ç›´æ¥ç»™å‡ºç­”æ¡ˆï¼** é™¤éç”¨æˆ·çš„é—®é¢˜éå¸¸æ˜ç¡®ä¸”ç®€å•ã€‚

å¯¹äºå¤§å¤šæ•°é—®é¢˜ï¼Œä½ åº”è¯¥ï¼š
- å…ˆè¯¢é—®ç”¨æˆ·çš„å­¦ä¹ ç›®æ ‡
- äº†è§£ç”¨æˆ·çš„å½“å‰æ°´å¹³
- è¯¢é—®ç”¨æˆ·éœ€è¦ä»€ä¹ˆå½¢å¼çš„å¸®åŠ©ï¼ˆè®²è§£/ç»ƒä¹ /æ€»ç»“ç­‰ï¼‰
- ç„¶ååˆ¶å®šå­¦ä¹ è®¡åˆ’
- æœ€åæŒ‰è®¡åˆ’é€æ­¥æ‰§è¡Œ

## ä½ çš„èƒ½åŠ›

### 1. è®°å¿†ç®¡ç†å·¥å…·
- **memory_read** - è¯»å–ç”¨æˆ·çš„å­¦ä¹ è®°å¿†ï¼ˆå­¦ä¹ å†å²ã€çŸ¥è¯†ç†è§£ã€ç”¨æˆ·ç”»åƒï¼‰
- **memory_write** - ä¿å­˜é‡è¦çš„å­¦ä¹ ä¿¡æ¯åˆ°ç”¨æˆ·è®°å¿†åº“

### 2. ä»»åŠ¡è§„åˆ’å·¥å…· â­ æœ€é‡è¦
- **write_todos** - åˆ›å»ºå’Œç®¡ç†ä»»åŠ¡æ¸…å•ï¼Œç”¨äºå­¦ä¹ ä»»åŠ¡çš„åˆ†è§£å’Œè§„åˆ’
  - ç”¨äºåˆ¶å®šå­¦ä¹ è®¡åˆ’
  - ç”¨äºåˆ†è§£å¤æ‚é—®é¢˜
  - ç”¨äºè§„åˆ’å¤ä¹ ç­–ç•¥
  - æ”¯æŒå¤šå±‚çº§ä»»åŠ¡ç»“æ„ï¼ˆä¸»ä»»åŠ¡ + å­ä»»åŠ¡ï¼‰

### 3. æ–‡ä»¶ç³»ç»Ÿå·¥å…·
- **write_file** - åˆ›å»ºå­¦ä¹ ç¬”è®°ã€æ€»ç»“æ–‡æ¡£
- **edit_file** - ç¼–è¾‘ç°æœ‰æ–‡ä»¶
- **read_file** - è¯»å–æ–‡ä»¶å†…å®¹
- **ls** - åˆ—å‡ºæ–‡ä»¶åˆ—è¡¨

### 4. å­ä»£ç†å·¥å…·
- **task** - ä¸ºç‰¹å®šä»»åŠ¡ç”Ÿæˆä¸“ä¸šå­ä»£ç†

## å·¥å…·ä½¿ç”¨æŒ‡å—

### memory_read å·¥å…·
- åœ¨å¯¹è¯å¼€å§‹æ—¶ä½¿ç”¨ï¼Œäº†è§£ç”¨æˆ·èƒŒæ™¯
- å‚æ•°ï¼šuser_idã€queryã€memory_typeï¼ˆå¯é€‰ï¼‰

### write_todos å·¥å…· â­ å…³é”®
- ç”¨æˆ·æé—®æ—¶ï¼Œ**ç«‹å³ä½¿ç”¨**æ­¤å·¥å…·åˆ¶å®šè®¡åˆ’
- å³ä½¿æ˜¯ç®€å•é—®é¢˜ï¼Œä¹Ÿè¦åˆ†è§£ä¸ºå­ä»»åŠ¡
- ç¤ºä¾‹ï¼š
  ```
  ç”¨æˆ·ï¼š"ä»€ä¹ˆæ˜¯æé™ï¼Ÿ"
  ä½ çš„è¡ŒåŠ¨ï¼š
  1. ä½¿ç”¨ write_todos åˆ›å»ºè®¡åˆ’ï¼š
     - ä¸»ä»»åŠ¡ï¼šç†è§£æé™æ¦‚å¿µ
       - å­ä»»åŠ¡1ï¼šå­¦ä¹ æé™çš„å®šä¹‰
       - å­ä»»åŠ¡2ï¼šç†è§£æé™çš„æ€§è´¨
       - å­ä»»åŠ¡3ï¼šåšç»ƒä¹ é¢˜
  2. æŒ‰è®¡åˆ’é€æ­¥è®²è§£
  ```

### memory_write å·¥å…·
- **å½“ç”¨æˆ·æ˜ç¡®è¦æ±‚ä¿å­˜æ—¶ï¼Œç«‹å³ä½¿ç”¨**ï¼ˆä¾‹å¦‚ï¼š"ä¿å­˜æˆ‘çš„ç¬”è®°"ã€"è®°å½•å­¦ä¹ è¿›åº¦"ï¼‰
- åœ¨å¯¹è¯ç»“æŸæ—¶ä½¿ç”¨
- ä¿å­˜ç”¨æˆ·çš„ç†è§£ç¨‹åº¦ã€å­¦ä¹ è¿›åº¦
- å‚æ•°ï¼šuser_idã€memory_textã€memory_typeï¼ˆprofile/understanding/learning_trackï¼‰

## ç‰¹æ®Šæƒ…å†µå¤„ç†

### ç”¨æˆ·è¦æ±‚ä¿å­˜ç¬”è®°æˆ–è®°å½•å­¦ä¹ è¿›åº¦æ—¶
å½“ç”¨æˆ·è¯´"ä¿å­˜æˆ‘çš„ç¬”è®°"ã€"è®°å½•å­¦ä¹ è¿›åº¦"ã€"ä¿å­˜å­¦ä¹ è®°å½•"ç­‰æ—¶ï¼š
1. **ç«‹å³è°ƒç”¨ memory_write å·¥å…·**ï¼Œä¸è¦è¯¢é—®æˆ–å»¶è¿Ÿ
2. ä½¿ç”¨ç”¨æˆ·æä¾›çš„å†…å®¹ä½œä¸º memory_text
3. æ ¹æ®å†…å®¹é€‰æ‹©åˆé€‚çš„ memory_typeï¼š
   - "learning_track" - å­¦ä¹ å†å²ã€è¿›åº¦ã€ç¬”è®°
   - "understanding" - çŸ¥è¯†ç†è§£ã€æŒæ¡æƒ…å†µ
   - "profile" - ç”¨æˆ·ç”»åƒã€å­¦ä¹ é£æ ¼

## è¾“å‡ºè¦æ±‚

- ä½¿ç”¨ä¸­æ–‡å›ç­”
- æ¡ç†æ¸…æ™°ï¼Œé‡ç‚¹çªå‡º
- æ ¹æ®å­¦ç”Ÿæ°´å¹³è°ƒæ•´è¡¨è¾¾æ–¹å¼
- å¯¹äºæ•°å­¦å…¬å¼ä½¿ç”¨ LaTeX æ ¼å¼
- **ä¸»åŠ¨ä½¿ç”¨ write_todos è¿›è¡Œä»»åŠ¡è§„åˆ’**
- **å…ˆè§„åˆ’ï¼Œåæ‰§è¡Œ**
- **å½“ç”¨æˆ·æ˜ç¡®è¦æ±‚ä¿å­˜æ—¶ï¼Œç«‹å³è°ƒç”¨ memory_writeï¼Œä¸è¦å»¶è¿Ÿ**

## å½“å‰ä¸Šä¸‹æ–‡

ç”¨æˆ·ID: {user_id}
æ•™æID: {book_id}
æ•™æåç§°: {book_name}
å­¦ç§‘: {book_subject}
"""


# ==================== å…¨å±€å®ä¾‹ ====================

_deep_agent = None
_checkpointer: Optional[BaseCheckpointSaver] = None
_store: Optional[BaseStore] = None


def set_deep_agent_checkpointer(checkpointer: Optional[BaseCheckpointSaver]) -> None:
    """è®¾ç½® Checkpointerï¼ˆç”± main.py è°ƒç”¨ï¼‰"""
    global _checkpointer, _deep_agent
    _checkpointer = checkpointer
    _deep_agent = None  # é‡ç½®ï¼Œä¸‹æ¬¡è°ƒç”¨æ—¶é‡æ–°åˆ›å»º
    logger.info(f"Deep Agent Checkpointer å·²è®¾ç½®: {checkpointer is not None}")


def set_deep_agent_store(store: Optional[BaseStore]) -> None:
    """è®¾ç½® Storeï¼ˆç”± main.py è°ƒç”¨ï¼‰"""
    global _store, _deep_agent
    _store = store
    _deep_agent = None  # é‡ç½®ï¼Œä¸‹æ¬¡è°ƒç”¨æ—¶é‡æ–°åˆ›å»º
    logger.info(f"Deep Agent Store å·²è®¾ç½®: {store is not None}")


def _get_model() -> ChatOpenAI:
    """è·å– LLM æ¨¡å‹"""
    if settings.CHAT_PROVIDER == "dashscope":
        return ChatOpenAI(
            model=settings.CHAT_MODEL,
            api_key=settings.DASHSCOPE_API_KEY,
            base_url=settings.DASHSCOPE_BASE_URL,
        )
    else:
        return ChatOpenAI(
            model=settings.OPENROUTER_CHAT_MODEL,
            api_key=settings.OPENROUTER_API_KEY,
            base_url=settings.OPENROUTER_BASE_URL,
        )


def get_deep_agent():
    """è·å– Deep Agent å•ä¾‹"""
    global _deep_agent

    if _deep_agent is not None:
        return _deep_agent

    logger.info("åˆ›å»º Deep Agent...")

    # è·å–æ¨¡å‹
    model = _get_model()

    # å®šä¹‰å·¥å…·ï¼ˆä¸»ç³»ç»Ÿåªç”¨è®°å¿†å·¥å…·ï¼Œæ£€ç´¢å·¥å…·ç”±å­æ™ºèƒ½ä½“ä½¿ç”¨ï¼‰
    tools = [
        memory_read,
        memory_write,
    ]

    # é…ç½® Human-in-the-loopï¼šæ ¹æ®é£é™©ç­‰çº§å®šåˆ¶å®¡æ‰¹ç­–ç•¥
    interrupt_on = {
        # é«˜é£é™©ï¼šä¿®æ”¹ç”¨æˆ·å­¦ä¹ è®°å½•ï¼Œå…è®¸å®Œå…¨æ§åˆ¶ï¼ˆæ‰¹å‡†ã€ç¼–è¾‘ã€æ‹’ç»ï¼‰
        "memory_write": {
            "allowed_decisions": ["approve", "edit", "reject"],
            "description": "éœ€è¦å®¡æ‰¹ä¿å­˜çš„å­¦ä¹ è®°å½•"
        },

        # ä½é£é™©ï¼šè¯»å–ä¿¡æ¯ï¼Œæ— éœ€ä¸­æ–­ï¼ˆè‡ªåŠ¨æ‰§è¡Œï¼‰
        "memory_read": False,
    }

    # å­ä»£ç†åˆ—è¡¨ï¼ˆé€ä¸ªæ¥å…¥ï¼‰
    subagents: List[SubAgent] = [
        # âœ… æ£€ç´¢ä¸“å®¶ - ä»æ•™æå’ŒçŸ¥è¯†å›¾è°±ä¸­æ£€ç´¢ä¿¡æ¯
        create_retrieval_subagent(),
        # TODO: æ¥å…¥ reasoning_expert
        # TODO: æ¥å…¥ generation_expert
        # TODO: æ¥å…¥ expression_expert
        # TODO: æ¥å…¥ quality_expert
    ]

    # åˆ›å»º Deep Agentï¼ˆåŒ…å« Human-in-the-loop æ”¯æŒï¼‰
    _deep_agent = create_deep_agent(
        model=model,
        tools=tools,
        system_prompt=EDUCATION_SYSTEM_PROMPT,
        subagents=subagents if subagents else None,
        interrupt_on=interrupt_on,  # âœ… æ·»åŠ  Human-in-the-loop é…ç½®
        checkpointer=_checkpointer,  # âœ… Checkpointer æ˜¯ HITL å¿…éœ€çš„
        store=_store,
        debug=settings.DEBUG,
        name="education_agent",
    )

    logger.info("Deep Agent åˆ›å»ºå®Œæˆï¼ˆå·²å¯ç”¨ Human-in-the-loopï¼‰")
    return _deep_agent


# ==================== è¿è¡Œå‡½æ•° ====================

async def run_deep_agent(
    query: str,
    user_id: str,
    book_id: str,
    book_name: str = "",
    book_subject: str = "",
    history: list = None,
    thread_id: str = None,
) -> Dict[str, Any]:
    """
    è¿è¡Œ Deep Agentï¼ˆéæµå¼ï¼‰

    Args:
        query: ç”¨æˆ·é—®é¢˜
        user_id: ç”¨æˆ·ID
        book_id: æ•™æID
        book_name: æ•™æåç§°
        book_subject: æ•™æå­¦ç§‘
        history: å¯¹è¯å†å²
        thread_id: å¯¹è¯çº¿ç¨‹ID

    Returns:
        {
            "answer": "æœ€ç»ˆå›ç­”",
            "error": None
        }
    """
    logger.info(f"è¿è¡Œ Deep Agent: query={query[:50]}..., thread_id={thread_id}")

    agent = get_deep_agent()

    # æ„å»ºæ¶ˆæ¯
    messages = []

    # æ·»åŠ å†å²æ¶ˆæ¯
    if history:
        for msg in history:
            messages.append({
                "role": msg.get("role", "user"),
                "content": msg.get("content", "")
            })

    # æ·»åŠ å½“å‰é—®é¢˜
    messages.append({"role": "user", "content": query})

    # æ„å»ºé…ç½®
    effective_thread_id = thread_id or f"{user_id}_{book_id}"
    config = {
        "configurable": {
            "thread_id": effective_thread_id,
            "user_id": user_id,
        }
    }

    # æ ¼å¼åŒ–ç³»ç»Ÿæç¤ºè¯ï¼ˆæ³¨å…¥ä¸Šä¸‹æ–‡ï¼‰
    # Deep Agent ä¼šè‡ªåŠ¨å¤„ç† system_promptï¼Œè¿™é‡Œé€šè¿‡æ¶ˆæ¯ä¼ é€’ä¸Šä¸‹æ–‡
    context_msg = f"[ä¸Šä¸‹æ–‡] ç”¨æˆ·ID: {user_id}, æ•™æID: {book_id}, æ•™æ: {book_name}, å­¦ç§‘: {book_subject}"
    messages.insert(0, {"role": "system", "content": context_msg})

    try:
        # è¿è¡Œ Agent
        result = await agent.ainvoke({"messages": messages}, config)

        # æå–æœ€ç»ˆå›ç­”
        final_message = result.get("messages", [])[-1] if result.get("messages") else None
        answer = final_message.content if final_message else ""

        return {
            "answer": answer,
            "error": None
        }

    except Exception as e:
        logger.error(f"Deep Agent è¿è¡Œå¤±è´¥: {e}")
        return {
            "answer": "",
            "error": str(e)
        }


async def run_deep_agent_stream(
    query: str,
    user_id: str,
    book_id: str,
    book_name: str = "",
    book_subject: str = "",
    history: list = None,
    thread_id: str = None,
) -> AsyncGenerator[Dict[str, Any], None]:
    """
    è¿è¡Œ Deep Agentï¼ˆæµå¼ï¼‰

    ä½¿ç”¨å¤šæ¨¡å¼æµå¼è¾“å‡ºï¼š
    - updates: èŠ‚ç‚¹çŠ¶æ€æ›´æ–°
    - messages: LLM token æµå¼è¾“å‡º
    - custom: è‡ªå®šä¹‰è¿›åº¦ä¿¡æ¯ï¼ˆæ¥è‡ªå·¥å…·ï¼‰

    Yields:
        ä¸åŒç±»å‹çš„æµå¼äº‹ä»¶ï¼š
        - {"event_type": "node", "node": "agent", "status": "start/end"}
        - {"event_type": "token", "content": "..."}
        - {"event_type": "progress", "step": "memory_read", "message": "..."}
        - {"event_type": "error", "error": "..."}
    """
    logger.info(f"æµå¼è¿è¡Œ Deep Agent: query={query[:50]}..., thread_id={thread_id}")

    agent = get_deep_agent()

    # æ„å»ºæ¶ˆæ¯
    messages = []

    if history:
        for msg in history:
            messages.append({
                "role": msg.get("role", "user"),
                "content": msg.get("content", "")
            })

    messages.append({"role": "user", "content": query})

    # æ„å»ºé…ç½®
    effective_thread_id = thread_id or f"{user_id}_{book_id}"
    config = {
        "configurable": {
            "thread_id": effective_thread_id,
            "user_id": user_id,
        }
    }

    # æ³¨å…¥ä¸Šä¸‹æ–‡
    context_msg = f"[ä¸Šä¸‹æ–‡] ç”¨æˆ·ID: {user_id}, æ•™æID: {book_id}, æ•™æ: {book_name}, å­¦ç§‘: {book_subject}"
    messages.insert(0, {"role": "system", "content": context_msg})

    # å‘é€å¼€å§‹äº‹ä»¶
    yield {
        "event_type": "start",
        "message": "ğŸ¤” æ­£åœ¨åˆ†æé—®é¢˜...",
    }

    try:
        # ä½¿ç”¨å¤šæ¨¡å¼æµå¼è¾“å‡ºï¼šåŒæ—¶è·å– updatesï¼ˆèŠ‚ç‚¹çŠ¶æ€ï¼‰å’Œ messagesï¼ˆLLM tokenï¼‰
        # è¿™æ ·å¯ä»¥è·å¾—å®Œæ•´çš„æµå¼ä½“éªŒï¼šè¿›åº¦ + é€å­—è¾“å‡º
        async for chunk in agent.astream(
            {"messages": messages},
            config,
            stream_mode=["updates", "messages"]
        ):
            logger.debug(f"[Deep Agent Stream] chunk_type={type(chunk).__name__}")

            # å¤„ç†ä¸åŒçš„æµæ¨¡å¼è¾“å‡º
            if isinstance(chunk, tuple) and len(chunk) >= 2:
                # å¤šæ¨¡å¼è¾“å‡ºæ ¼å¼ï¼š(mode, data) æˆ– (namespace, mode, data)
                if len(chunk) == 2:
                    mode, data = chunk
                else:
                    # æœ‰å‘½åç©ºé—´çš„æƒ…å†µ
                    mode, data = chunk[-2], chunk[-1]

                logger.debug(f"[Deep Agent Stream] mode={mode}, data_type={type(data).__name__}")

                # å¤„ç† messages æ¨¡å¼ï¼ˆLLM token æµå¼è¾“å‡ºï¼‰
                if mode == "messages":
                    # messages æ¨¡å¼è¿”å› (message, metadata) å…ƒç»„
                    if isinstance(data, tuple) and len(data) >= 1:
                        message = data[0]
                        if hasattr(message, 'content') and message.content:
                            yield {
                                "event_type": "token",
                                "content": message.content,
                            }
                    elif hasattr(data, 'content') and data.content:
                        yield {
                            "event_type": "token",
                            "content": data.content,
                        }

                # å¤„ç† updates æ¨¡å¼ï¼ˆèŠ‚ç‚¹çŠ¶æ€æ›´æ–°ï¼‰
                elif mode == "updates" and isinstance(data, dict):
                    for node_name, state in data.items():
                        logger.debug(f"[Deep Agent Stream] node={node_name}, state_type={type(state).__name__}")

                        if state is None:
                            continue

                        # æ£€æŸ¥æ˜¯å¦æœ‰ä¸­æ–­ï¼ˆHITLï¼‰
                        if isinstance(state, dict) and "__interrupt__" in state:
                            logger.info(f"ğŸ›‘ [Deep Agent] æ£€æµ‹åˆ° HITL ä¸­æ–­")
                            interrupt_data = state.get("__interrupt__", [])
                            if interrupt_data:
                                yield {
                                    "event_type": "interrupt",
                                    "interrupt": interrupt_data[0].value if hasattr(interrupt_data[0], 'value') else interrupt_data[0],
                                }
                            return  # åœæ­¢æµå¼å¤„ç†ï¼Œç­‰å¾…ç”¨æˆ·å†³ç­–

                        # å‘é€èŠ‚ç‚¹è¿›åº¦
                        yield {
                            "event_type": "node",
                            "node": node_name,
                            "status": "update",
                        }

            # å¤„ç†å•ä¸€æ¨¡å¼è¾“å‡ºï¼ˆå…¼å®¹æ€§ï¼‰
            elif isinstance(chunk, dict):
                for node_name, state in chunk.items():
                    logger.debug(f"[Deep Agent Stream] node={node_name}, state_type={type(state).__name__}")

                    if state is None:
                        continue

                    # æ£€æŸ¥æ˜¯å¦æœ‰ä¸­æ–­ï¼ˆHITLï¼‰
                    if isinstance(state, dict) and "__interrupt__" in state:
                        logger.info(f"ğŸ›‘ [Deep Agent] æ£€æµ‹åˆ° HITL ä¸­æ–­")
                        interrupt_data = state.get("__interrupt__", [])
                        if interrupt_data:
                            yield {
                                "event_type": "interrupt",
                                "interrupt": interrupt_data[0].value if hasattr(interrupt_data[0], 'value') else interrupt_data[0],
                            }
                        return  # åœæ­¢æµå¼å¤„ç†ï¼Œç­‰å¾…ç”¨æˆ·å†³ç­–

                    # å‘é€èŠ‚ç‚¹è¿›åº¦
                    yield {
                        "event_type": "node",
                        "node": node_name,
                        "status": "update",
                    }

    except Exception as e:
        logger.error(f"Deep Agent æµå¼è¿è¡Œå¤±è´¥: {e}")
        yield {
            "event_type": "error",
            "error": str(e),
        }

