"""
RAG æ£€ç´¢æ¨¡å—
å®ç°å‘é‡æ£€ç´¢å’Œä¸Šä¸‹æ–‡æ„å»ºï¼Œæ”¯æŒå¤šè½®å¯¹è¯ã€æŸ¥è¯¢æ”¹å†™ã€é‡æ’åºå’Œæ··åˆæ£€ç´¢
"""

import logging
import json
import re
from typing import List, Dict, Any, Optional, Tuple
import httpx

from config import settings
from .vector_store import VectorStore
from .document_processor import OpenRouterEmbedding
from .conversation_memory import get_memory, ConversationMemory

logger = logging.getLogger(__name__)

# Context å­—ç¬¦æ•°ç†”æ–­é˜ˆå€¼ï¼ˆé˜²æ­¢è¶…è¿‡æ¨¡å‹ä¸Šä¸‹æ–‡é™åˆ¶ï¼‰
CONTEXT_CHAR_LIMIT = 12000  # çº¦ 3000-4000 tokens

# Rerank é…ç½®
RERANK_ENABLED = True  # æ˜¯å¦å¯ç”¨é‡æ’åº
RERANK_TOP_N = 3  # é‡æ’åºåä¿ç•™çš„æ•°é‡

# æ··åˆæ£€ç´¢é…ç½®
HYBRID_SEARCH_ENABLED = True  # æ˜¯å¦å¯ç”¨æ··åˆæ£€ç´¢
KEYWORD_BOOST_WEIGHT = 0.3  # å…³é”®è¯åŒ¹é…çš„æƒé‡æå‡


class RAGRetriever:
    """RAG æ£€ç´¢å™¨"""
    
    def __init__(self):
        """åˆå§‹åŒ–æ£€ç´¢å™¨"""
        self.embedding = OpenRouterEmbedding()
        self.vector_store = VectorStore()
        self.chat_model = settings.CHAT_MODEL
        self.memory = get_memory()
        logger.info(f"RAG æ£€ç´¢å™¨åˆå§‹åŒ–å®Œæˆï¼ŒChat Model: {self.chat_model}")
    
    async def rewrite_query(
        self,
        query: str,
        history: Optional[List[Dict[str, str]]] = None
    ) -> str:
        """æ ¹æ®å†å²å¯¹è¯æ”¹å†™æŸ¥è¯¢ï¼Œè§£å†³æŒ‡ä»£ä¸æ¸…é—®é¢˜"""
        if not history or len(history) == 0:
            return query

        recent_history = history[-6:] if len(history) > 6 else history
        history_text = "\n".join([
            f"{'ç”¨æˆ·' if msg['role'] == 'user' else 'AI'}: {msg['content'][:200]}"
            for msg in recent_history
        ])

        rewrite_prompt = f"""ä½ æ˜¯ä¸€ä¸ªæŸ¥è¯¢æ”¹å†™åŠ©æ‰‹ã€‚æ ¹æ®å¯¹è¯å†å²ï¼Œå°†ç”¨æˆ·çš„å½“å‰é—®é¢˜æ”¹å†™æˆä¸€ä¸ªç‹¬ç«‹ã€å®Œæ•´çš„æŸ¥è¯¢è¯­å¥ã€‚

å¯¹è¯å†å²ï¼š
{history_text}

å½“å‰é—®é¢˜ï¼š{query}

æ”¹å†™è§„åˆ™ï¼š
1. è§£å†³ä»£è¯æŒ‡ä»£ï¼ˆå¦‚"å®ƒ"ã€"è¿™ä¸ª"ã€"é‚£ä¸ª"ç­‰ï¼‰
2. è¡¥å……çœç•¥çš„ä¸»è¯­æˆ–å®¾è¯­
3. ä¿æŒåŸæ„ï¼Œä¸è¦æ·»åŠ é¢å¤–ä¿¡æ¯
4. å¦‚æœå½“å‰é—®é¢˜å·²ç»è¶³å¤Ÿæ¸…æ™°ï¼Œç›´æ¥è¿”å›åŸé—®é¢˜
5. åªè¿”å›æ”¹å†™åçš„é—®é¢˜ï¼Œä¸è¦æœ‰ä»»ä½•è§£é‡Š

æ”¹å†™åçš„é—®é¢˜ï¼š"""

        try:
            async with httpx.AsyncClient(timeout=30.0) as client:
                response = await client.post(
                    f"{settings.OPENROUTER_BASE_URL}/chat/completions",
                    headers={
                        "Authorization": f"Bearer {settings.OPENROUTER_API_KEY}",
                        "Content-Type": "application/json",
                    },
                    json={
                        "model": self.chat_model,
                        "messages": [{"role": "user", "content": rewrite_prompt}],
                        "temperature": 0.1,
                        "max_tokens": 200,
                    }
                )
                response.raise_for_status()
                data = response.json()
                rewritten = data["choices"][0]["message"]["content"].strip().strip('"\'')
                logger.info(f"æŸ¥è¯¢æ”¹å†™: '{query}' -> '{rewritten}'")
                return rewritten
        except Exception as e:
            logger.warning(f"æŸ¥è¯¢æ”¹å†™å¤±è´¥ï¼Œä½¿ç”¨åŸæŸ¥è¯¢: {e}")
            return query

    def _extract_keywords(self, query: str) -> List[str]:
        """ä»æŸ¥è¯¢ä¸­æå–å…³é”®è¯ï¼ˆç”¨äºæ··åˆæ£€ç´¢ï¼‰"""
        keywords = []
        # æå–è‹±æ–‡å•è¯å’Œæ•°å­—
        english_pattern = r'[A-Za-z][A-Za-z0-9_\-\.]*[A-Za-z0-9]|[A-Za-z]'
        english_matches = re.findall(english_pattern, query)
        keywords.extend([w for w in english_matches if len(w) >= 2])
        # æå–æ•°å­—
        number_pattern = r'\d+\.?\d*'
        number_matches = re.findall(number_pattern, query)
        keywords.extend(number_matches)
        # æå–ä¸­æ–‡è¯ç»„
        chinese_pattern = r'[\u4e00-\u9fff]{2,4}'
        chinese_matches = re.findall(chinese_pattern, query)
        keywords.extend(chinese_matches)
        return list(set(keywords))

    def _keyword_match_score(self, text: str, keywords: List[str]) -> float:
        """è®¡ç®—æ–‡æœ¬ä¸å…³é”®è¯çš„åŒ¹é…åˆ†æ•°"""
        if not keywords:
            return 0.0
        text_lower = text.lower()
        matched = sum(1 for kw in keywords if kw.lower() in text_lower)
        return matched / len(keywords)

    def retrieve(
        self,
        query: str,
        top_k: int = 5,
        filter_expr: Optional[str] = None
    ) -> List[Dict[str, Any]]:
        """æ£€ç´¢ç›¸å…³æ–‡æ¡£ç‰‡æ®µï¼ˆæ”¯æŒæ··åˆæ£€ç´¢ï¼‰"""
        logger.info(f"å¼€å§‹æ£€ç´¢ï¼Œquery: {query[:50]}..., top_k: {top_k}")

        query_embedding = self.embedding.get_text_embedding(query)
        search_top_k = top_k * 2 if RERANK_ENABLED else top_k
        results = self.vector_store.search(
            query_embedding=query_embedding,
            top_k=search_top_k,
            filter_expr=filter_expr
        )

        # æ··åˆæ£€ç´¢ï¼šå…³é”®è¯åŒ¹é…åŠ æƒ
        if HYBRID_SEARCH_ENABLED and results:
            keywords = self._extract_keywords(query)
            if keywords:
                logger.info(f"æ··åˆæ£€ç´¢ï¼šæå–å…³é”®è¯ {keywords}")
                for result in results:
                    text = result.get("text", "")
                    keyword_score = self._keyword_match_score(text, keywords)
                    original_score = result.get("score", 0)
                    result["keyword_score"] = keyword_score
                    result["score"] = original_score + (keyword_score * KEYWORD_BOOST_WEIGHT)
                results.sort(key=lambda x: x["score"], reverse=True)

        # ğŸ†• æ–°å¢ï¼šè¿‡æ»¤æ‰ç›¸å…³åº¦è¿‡ä½çš„å™ªéŸ³
        # é˜ˆå€¼å»ºè®®ï¼š0.5 - 0.6 (DashVector çš„ score é€šå¸¸æ˜¯ 0-1 æˆ–æ›´é«˜ï¼Œè§†è·ç¦»ç±»å‹è€Œå®š)
        # å¦‚æœæ˜¯ Cosine è·ç¦»ï¼Œé€šå¸¸ 0.7 ä»¥ä¸‹å°±å¾ˆä¸ç›¸å…³äº†
        SCORE_THRESHOLD = 0.5 
        
        valid_results = [r for r in results if r.get("score", 0) >= SCORE_THRESHOLD]
        
        logger.info(f"æ£€ç´¢å®Œæˆï¼ŒåŸå§‹: {len(results)}ï¼Œæœ‰æ•ˆ(>{SCORE_THRESHOLD}): {len(valid_results)}")
        return valid_results

    async def rerank(
        self,
        query: str,
        results: List[Dict[str, Any]],
        top_n: int = RERANK_TOP_N
    ) -> List[Dict[str, Any]]:
        """ä½¿ç”¨ LLM å¯¹æ£€ç´¢ç»“æœè¿›è¡Œé‡æ’åº"""
        if not results or len(results) <= top_n:
            return results
        
        candidates = []
        for i, result in enumerate(results):
            text = result.get("text", "")[:500]
            candidates.append(f"[{i+1}] {text}")
        
        candidates_text = "\n\n".join(candidates)
        
        rerank_prompt = f"""ä½ æ˜¯ä¸€ä¸ªæ–‡æ¡£ç›¸å…³æ€§è¯„ä¼°ä¸“å®¶ã€‚è¯·æ ¹æ®ç”¨æˆ·é—®é¢˜ï¼Œå¯¹ä»¥ä¸‹å€™é€‰æ–‡æ¡£ç‰‡æ®µè¿›è¡Œç›¸å…³æ€§æ’åºã€‚

ç”¨æˆ·é—®é¢˜ï¼š{query}

å€™é€‰æ–‡æ¡£ï¼š
{candidates_text}

è¯·æŒ‰ç›¸å…³æ€§ä»é«˜åˆ°ä½ï¼Œè¿”å›æœ€ç›¸å…³çš„ {top_n} ä¸ªæ–‡æ¡£çš„ç¼–å·ã€‚
åªè¿”å›ç¼–å·ï¼Œç”¨é€—å·åˆ†éš”ï¼Œä¾‹å¦‚ï¼š3,1,5

æœ€ç›¸å…³çš„æ–‡æ¡£ç¼–å·ï¼š"""

        try:
            async with httpx.AsyncClient(timeout=30.0) as client:
                response = await client.post(
                    f"{settings.OPENROUTER_BASE_URL}/chat/completions",
                    headers={
                        "Authorization": f"Bearer {settings.OPENROUTER_API_KEY}",
                        "Content-Type": "application/json",
                    },
                    json={
                        "model": self.chat_model,
                        "messages": [{"role": "user", "content": rerank_prompt}],
                        "temperature": 0.1,
                        "max_tokens": 50,
                    }
                )
                response.raise_for_status()
                data = response.json()
                ranking_str = data["choices"][0]["message"]["content"].strip()
                
                indices = []
                for num in re.findall(r'\d+', ranking_str):
                    idx = int(num) - 1
                    if 0 <= idx < len(results) and idx not in indices:
                        indices.append(idx)
                
                if indices:
                    reranked = [results[i] for i in indices[:top_n]]
                    logger.info(f"Rerank å®Œæˆï¼š{len(results)} -> {len(reranked)}")
                    return reranked
                else:
                    return results[:top_n]
        except Exception as e:
            logger.warning(f"Rerank å¤±è´¥: {e}")
            return results[:top_n]
    
    def build_context(
        self,
        results: List[Dict[str, Any]],
        max_chars: int = CONTEXT_CHAR_LIMIT
    ) -> Tuple[str, List[Dict[str, Any]]]:
        """æ„å»ºä¸Šä¸‹æ–‡ï¼ˆå¸¦å­—ç¬¦æ•°ç†”æ–­å™¨å’Œå¼•ç”¨æ ‡è®°ï¼‰"""
        if not results:
            return "", []
        
        context_parts = []
        used_results = []
        current_chars = 0
        
        for i, result in enumerate(results, 1):
            text = result.get("text", "")
            score = result.get("score", 0)
            part = f"[æ¥æº{i}] (ç›¸å…³åº¦: {score:.3f})\n{text}"
            part_len = len(part)
            
            if current_chars + part_len > max_chars:
                logger.warning(f"Context ç†”æ–­ï¼šç¬¬ {i} ä¸ªç‰‡æ®µè¶…è¿‡é™åˆ¶")
                break
            
            context_parts.append(part)
            used_results.append({**result, "citation_id": i})
            current_chars += part_len + 10
        
        final_context = "\n\n---\n\n".join(context_parts)
        logger.info(f"Context æ„å»ºå®Œæˆï¼š{len(context_parts)} ä¸ªç‰‡æ®µ")
        return final_context, used_results
    
    def _build_messages(
        self,
        query: str,
        context: str,
        system_prompt: Optional[str] = None,
        history: Optional[List[Dict[str, str]]] = None,
        summary: Optional[str] = None
    ) -> list:
        """æ„å»ºæ¶ˆæ¯åˆ—è¡¨ï¼Œæ”¯æŒå¤šè½®å¯¹è¯ã€æ‘˜è¦æ³¨å…¥å’Œå¼•ç”¨æº¯æº"""
        
        # 1. åŠ¨æ€å†³å®š System Prompt
        # å¦‚æœæ²¡æœ‰å‚è€ƒèµ„æ–™ï¼Œå°±æŠŠå®ƒå˜æˆä¸€ä¸ªçº¯èŠå¤©åŠ©æ‰‹ï¼Œä¸è¦ç»™å®ƒ"å¼•ç”¨"çš„å‹åŠ›
        if not context or not context.strip():
            base_system_prompt = """ä½ æ˜¯ç”¨æˆ·çš„å¥½æœ‹å‹ï¼Œä¸€ä¸ªæ´»æ³¼ã€æœ‰è¶£ã€å–„è§£äººæ„çš„èŠå¤©ä¼™ä¼´ã€‚

ã€æœ€é‡è¦çš„è§„åˆ™ - è¯·åŠ¡å¿…éµå®ˆã€‘ï¼š
1. **ä½ ç°åœ¨æ˜¯åœ¨é—²èŠï¼Œä¸æ˜¯åœ¨æŸ¥èµ„æ–™ï¼** ä¸è¦è¯´"è¯·æå‡ºå…·ä½“é—®é¢˜"ã€"æˆ‘ä¼šæ ¹æ®èµ„æ–™å›ç­”"ä¹‹ç±»çš„è¯ã€‚
2. **åƒæœ‹å‹ä¸€æ ·è¯´è¯**ï¼šç”¨æˆ·è¯´"å¥½å§"ï¼Œä½ å¯ä»¥è¯´"æ€ä¹ˆå•¦ï¼Œæ˜¯ä¸æ˜¯æœ‰ç‚¹æ— èŠï¼ŸèŠç‚¹åˆ«çš„ï¼Ÿ"
3. **å›é¡¾å¯¹è¯å†å²**ï¼šç”¨æˆ·é—®"æˆ‘åˆšæ‰è¯´äº†ä»€ä¹ˆ"ï¼Œç›´æ¥çœ‹ä¸Šé¢çš„å¯¹è¯å†å²å‘Šè¯‰ä»–ï¼
4. **æœ‰ä¸ªæ€§**ï¼šå¯ä»¥å¼€ç©ç¬‘ã€å¯ä»¥åæ§½ã€å¯ä»¥è¡¨è¾¾æƒ…ç»ªï¼Œä¸è¦åƒæœºå™¨äººã€‚
5. **ç®€çŸ­è‡ªç„¶**ï¼šä¸è¦é•¿ç¯‡å¤§è®ºï¼Œåƒå¾®ä¿¡èŠå¤©ä¸€æ ·ç®€çŸ­ã€‚

ã€ç¦æ­¢è¯´çš„è¯ã€‘ï¼š
- "è¯·é—®æ‚¨æœ‰ä»€ä¹ˆå…·ä½“é—®é¢˜éœ€è¦æˆ‘å¸®åŠ©è§£ç­”çš„ï¼Ÿ"
- "è¯·æå‡ºæ‚¨çš„å…·ä½“é—®é¢˜"
- "æˆ‘ä¼šæ ¹æ®å‚è€ƒèµ„æ–™ä¸ºæ‚¨è§£ç­”"
- "æŠ±æ­‰ï¼Œæˆ‘æ— æ³•æ ¹æ®æ‚¨çš„è¯·æ±‚æä¾›ä¿¡æ¯"

ã€ä½ åº”è¯¥è¯´çš„è¯ã€‘ï¼š
- "å“ˆå“ˆï¼Œæ€ä¹ˆäº†ï¼Ÿ"
- "å—¯å—¯ï¼Œè¿˜æœ‰ä»€ä¹ˆæƒ³èŠçš„å—ï¼Ÿ"
- "ä½ åˆšæ‰é—®çš„æ˜¯xxxï¼Œæˆ‘è®°å¾—å‘¢ï¼"
- "è¿™é—¨è¯¾å˜›ï¼Œçœ‹ä½ åŸºç¡€å•¦~"
"""
        else:
            # å¦‚æœæœ‰å‚è€ƒèµ„æ–™ï¼Œå¯ç”¨"åŠ©æ•™æ¨¡å¼"ï¼Œä½†ä¾ç„¶ä¿æŒäº²å’ŒåŠ›
            base_system_prompt = system_prompt or """ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šä½†äº²åˆ‡çš„ AI åŠ©æ•™ã€‚

ã€æ ¸å¿ƒåŸåˆ™ã€‘ï¼š
1. **æœ‰èµ„æ–™å°±ç”¨èµ„æ–™**ï¼šå›ç­”çŸ¥è¯†ç‚¹æ—¶ï¼ŒåŸºäºå‚è€ƒèµ„æ–™ï¼Œæ ‡æ³¨[æ¥æºX]ã€‚
2. **æ²¡èµ„æ–™å°±ç”¨å¸¸è¯†**ï¼šèµ„æ–™é‡Œæ²¡æœ‰çš„ï¼Œç”¨ä½ çš„çŸ¥è¯†è¡¥å……ï¼Œä¸è¦è¯´"èµ„æ–™é‡Œæ²¡æœ‰"ã€‚
3. **é—²èŠå°±é—²èŠ**ï¼šç”¨æˆ·æ‰“æ‹›å‘¼ã€è¯´"å¥½å§"ã€é—®"åˆšæ‰è¯´äº†ä»€ä¹ˆ"ï¼Œå°±æ­£å¸¸èŠå¤©ï¼Œåˆ«æèµ„æ–™ã€‚
4. **ç®€æ´æœ‰è¶£**ï¼šä¸è¦é•¿ç¯‡å¤§è®ºï¼Œåƒä¸ªçœŸäººè€å¸ˆä¸€æ ·è¯´è¯ã€‚
"""

        # 2. æ³¨å…¥æ‘˜è¦ï¼ˆé•¿æœŸè®°å¿†ï¼‰
        if summary:
            full_system_prompt = f"{base_system_prompt}

[ä¹‹å‰çš„å¯¹è¯æ‘˜è¦ï¼ˆè¿™æ˜¯ç”¨æˆ·çš„é‡è¦èƒŒæ™¯ï¼Œè¯·è®°ä½ï¼‰]
{summary}
[æ‘˜è¦ç»“æŸ]"
        else:
            full_system_prompt = base_system_prompt

        messages = [{"role": "system", "content": full_system_prompt}]

        # 3. æ³¨å…¥çŸ­æœŸå†å²
        if history:
            for msg in history:
                messages.append({"role": msg["role"], "content": msg["content"]})

        # 4. ã€æœ€å…³é”®ä¿®æ”¹ã€‘åŠ¨æ€æ„å»ºç”¨æˆ·æ¶ˆæ¯
        # å¦‚æœæ²¡æœ‰ contextï¼Œå°±ä¸è¦å‘"å‚è€ƒèµ„æ–™"è¿™å‡ ä¸ªå­—ï¼Œé˜²æ­¢ AI çŠ¯å‚»
        if context and context.strip():
            final_user_content = f"""### å‚è€ƒèµ„æ–™ï¼ˆè¯·åœ¨å›ç­”ä¸­å¼•ç”¨ï¼‰ï¼š
{context}

---

### ç”¨æˆ·é—®é¢˜ï¼š
{query}"""
        else:
            # æ²¡èµ„æ–™æ—¶ï¼Œå°±æ˜¯çº¯èŠå¤©ï¼
            final_user_content = query

        messages.append({
            "role": "user",
            "content": final_user_content
        })

        return messages

    async def generate_answer(
        self,
        query: str,
        context: str,
        system_prompt: Optional[str] = None,
        history: Optional[List[Dict[str, str]]] = None,
        summary: Optional[str] = None
    ) -> str:
        """åŸºäºä¸Šä¸‹æ–‡ç”Ÿæˆå›ç­”ï¼ˆéæµå¼ï¼‰"""
        messages = self._build_messages(query, context, system_prompt, history, summary)
        logger.info(f"å¼€å§‹ç”Ÿæˆå›ç­”ï¼Œæ¨¡å‹: {self.chat_model}")

        async with httpx.AsyncClient(timeout=120.0) as client:
            response = await client.post(
                f"{settings.OPENROUTER_BASE_URL}/chat/completions",
                headers={
                    "Authorization": f"Bearer {settings.OPENROUTER_API_KEY}",
                    "Content-Type": "application/json",
                    "HTTP-Referer": settings.OPENROUTER_SITE_URL or "",
                    "X-Title": settings.OPENROUTER_SITE_NAME or "",
                },
                json={
                    "model": self.chat_model,
                    "messages": messages,
                    "temperature": 0.85,
                    "max_tokens": 2000,
                }
            )
            response.raise_for_status()
            data = response.json()
            answer = data["choices"][0]["message"]["content"]
            logger.info(f"å›ç­”ç”Ÿæˆå®Œæˆï¼Œé•¿åº¦: {len(answer)}")
            return answer

    async def generate_answer_stream(
        self,
        query: str,
        context: str,
        system_prompt: Optional[str] = None,
        history: Optional[List[Dict[str, str]]] = None,
        summary: Optional[str] = None
    ):
        """åŸºäºä¸Šä¸‹æ–‡ç”Ÿæˆå›ç­”ï¼ˆæµå¼ï¼‰"""
        messages = self._build_messages(query, context, system_prompt, history, summary)
        # è°ƒè¯•æ—¥å¿—ï¼šç¡®è®¤å¼•ç”¨è§„åˆ™æ˜¯å¦ç”Ÿæ•ˆ
        if messages and messages[0].get("role") == "system":
            sys_content = messages[0].get("content", "")
            has_citation_rule = "[æ¥æº" in sys_content or "æ¥æºX" in sys_content
            logger.info(f"å¼€å§‹æµå¼ç”Ÿæˆå›ç­”ï¼Œæ¨¡å‹: {self.chat_model}, å¼•ç”¨è§„åˆ™: {'?' if has_citation_rule else '?'}")

        async with httpx.AsyncClient(timeout=120.0) as client:
            async with client.stream(
                "POST",
                f"{settings.OPENROUTER_BASE_URL}/chat/completions",
                headers={
                    "Authorization": f"Bearer {settings.OPENROUTER_API_KEY}",
                    "Content-Type": "application/json",
                    "HTTP-Referer": settings.OPENROUTER_SITE_URL or "",
                    "X-Title": settings.OPENROUTER_SITE_NAME or "",
                },
                json={
                    "model": self.chat_model,
                    "messages": messages,
                    "temperature": 0.85,
                    "max_tokens": 2000,
                    "stream": True,
                }
            ) as response:
                response.raise_for_status()
                async for line in response.aiter_lines():
                    if line.startswith("data: "):
                        data_str = line[6:]
                        if data_str.strip() == "[DONE]":
                            break
                        try:
                            data = json.loads(data_str)
                            delta = data.get("choices", [{}])[0].get("delta", {})
                            content = delta.get("content", "")
                            if content:
                                yield content
                        except json.JSONDecodeError:
                            continue

    def _extract_citations(
        self,
        answer: str,
        sources: List[Dict[str, Any]]
    ) -> List[Dict[str, Any]]:
        """ä»å›ç­”ä¸­æå–å¼•ç”¨ä¿¡æ¯"""
        citations = []
        citation_pattern = r'\[æ¥æº(\d+)\]'
        matches = re.findall(citation_pattern, answer)
        
        seen_ids = set()
        for match in matches:
            citation_id = int(match)
            if citation_id not in seen_ids and citation_id <= len(sources):
                seen_ids.add(citation_id)
                source = sources[citation_id - 1]
                citations.append({
                    "citation_id": citation_id,
                    "text_preview": source.get("text", "")[:200] + "...",
                    "score": source.get("score", 0),
                    "metadata": source.get("metadata", {})
                })
        return citations
    
    async def query(
        self,
        question: str,
        top_k: int = 5,
        filter_expr: Optional[str] = None,
        system_prompt: Optional[str] = None,
        history: Optional[List[Dict[str, str]]] = None,
        user_id: Optional[str] = None,
        book_id: Optional[str] = None,
        enable_rerank: bool = RERANK_ENABLED
    ) -> Dict[str, Any]:
        """
        å®Œæ•´çš„ RAG æŸ¥è¯¢æµç¨‹ï¼ˆæ”¯æŒå¤šè½®å¯¹è¯ã€é•¿æœŸè®°å¿†ã€é‡æ’åºå’Œå¼•ç”¨æº¯æºï¼‰
        """
        # è®°å¿†æ¨¡å—å¤„ç†
        compressed_history = history or []
        summary = None
        
        if user_id and book_id and history:
            try:
                compressed_history, summary = await self.memory.check_and_compress(
                    user_id=user_id, book_id=book_id, history=history
                )
                logger.info(f"è®°å¿†å¤„ç†ï¼š{len(history)} -> {len(compressed_history)} æ¡")
            except Exception as e:
                logger.error(f"è®°å¿†å¤„ç†å¤±è´¥: {e}")
                compressed_history = history
        elif user_id and book_id:
            try:
                summary = await self.memory.get_summary(user_id, book_id)
            except Exception as e:
                logger.warning(f"è·å–æ‘˜è¦å¤±è´¥: {e}")

        # 1. æŸ¥è¯¢æ”¹å†™
        rewritten_query = await self.rewrite_query(question, compressed_history)

        # 2. æ£€ç´¢ï¼ˆåŒ…å«æ··åˆæ£€ç´¢ï¼‰
        results = self.retrieve(rewritten_query, top_k, filter_expr)

        # ?? ã€ä¿®æ”¹ç‚¹ã€‘åˆ é™¤äº† if not results çš„æ‹¦æˆªå—
        # å³ä½¿ results ä¸ºç©ºï¼Œä¹Ÿè¦ç»§ç»­å¾€ä¸‹æ‰§è¡Œï¼Œè¿›å…¥ LLM ç”Ÿæˆç¯èŠ‚

        # 3. é‡æ’åºï¼ˆå¯é€‰ï¼‰
        if enable_rerank and RERANK_ENABLED and results:  # æ³¨æ„ï¼šåŠ äº† results å­˜åœ¨çš„åˆ¤æ–­é˜²æ­¢æŠ¥é”™
            results = await self.rerank(rewritten_query, results, top_n=top_k)

        # 4. æ„å»ºä¸Šä¸‹æ–‡ï¼ˆå¸¦å¼•ç”¨æ ‡è®°ï¼‰
        context, used_sources = self.build_context(results)

        # 5. ç”Ÿæˆå›ç­”ï¼ˆå¸¦å¼•ç”¨æº¯æºï¼‰
        # ?? æœ€ç»ˆä¿®æ­£ï¼šå¼ºåˆ¶ system_prompt=Noneï¼Œç¡®ä¿å†…ç½®å¼•ç”¨è§„åˆ™ç”Ÿæ•ˆ
        answer = await self.generate_answer(
            question, context, None, compressed_history, summary  # â† å¼ºåˆ¶ None
        )

        # 6. æå–å›ç­”ä¸­çš„å¼•ç”¨
        citations = self._extract_citations(answer, used_sources)

        return {
            "answer": answer,
            "sources": used_sources,
            "citations": citations,
            "has_context": True
        }
